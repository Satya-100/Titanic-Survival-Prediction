{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Titanic Survival Prediction\n"
      ],
      "metadata": {
        "id": "vjxnuQIaN38j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Load train and test datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Display basic information about the datasets\n",
        "print(\"Train dataset info:\")\n",
        "print(train_df.info())\n",
        "print(\"\\nTest dataset info:\")\n",
        "print(test_df.info())\n",
        "\n",
        "# Display the first few rows of the train dataset\n",
        "print(\"\\nTrain dataset head:\")\n",
        "print(train_df.head())\n",
        "\n",
        "# Display the first few rows of the test dataset\n",
        "print(\"\\nTest dataset head:\")\n",
        "print(test_df.head())\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nTrain dataset summary statistics:\")\n",
        "print(train_df.describe())\n",
        "\n",
        "# Summary statistics for categorical variables\n",
        "print(\"\\nTrain dataset categorical summary statistics:\")\n",
        "print(train_df.describe(include=['O']))\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in train dataset:\")\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in test dataset:\")\n",
        "print(test_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPN4YZ3OOFGm",
        "outputId": "a81b86a9-3bad-47d4-c5f0-cd8f2218022e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "\n",
            "Test dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n",
            "None\n",
            "\n",
            "Train dataset head:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "Test dataset head:\n",
            "   PassengerId  Pclass                                          Name     Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    male   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
            "3          895       3                              Wirz, Mr. Albert    male   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
            "\n",
            "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
            "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
            "1  47.0      1      0   363272   7.0000   NaN        S  \n",
            "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
            "3  27.0      0      0   315154   8.6625   NaN        S  \n",
            "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
            "\n",
            "Train dataset summary statistics:\n",
            "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
            "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
            "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
            "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
            "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
            "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
            "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
            "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
            "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  891.000000  891.000000  \n",
            "mean     0.381594   32.204208  \n",
            "std      0.806057   49.693429  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    7.910400  \n",
            "50%      0.000000   14.454200  \n",
            "75%      0.000000   31.000000  \n",
            "max      6.000000  512.329200  \n",
            "\n",
            "Train dataset categorical summary statistics:\n",
            "                           Name   Sex  Ticket    Cabin Embarked\n",
            "count                       891   891     891      204      889\n",
            "unique                      891     2     681      147        3\n",
            "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
            "freq                          1   577       7        4      644\n",
            "\n",
            "Missing values in train dataset:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "\n",
            "Missing values in test dataset:\n",
            "PassengerId      0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "RvaXYdWOOJi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values\n",
        "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
        "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
        "\n",
        "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
        "test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
        "\n",
        "# Feature engineering\n",
        "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
        "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
        "\n",
        "train_df['IsAlone'] = 0\n",
        "train_df.loc[train_df['FamilySize'] == 1, 'IsAlone'] = 1\n",
        "\n",
        "test_df['IsAlone'] = 0\n",
        "test_df.loc[test_df['FamilySize'] == 1, 'IsAlone'] = 1\n",
        "\n",
        "# Encoding categorical variables\n",
        "train_df = pd.get_dummies(train_df, columns=['Sex', 'Embarked'])\n",
        "test_df = pd.get_dummies(test_df, columns=['Sex', 'Embarked'])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "drop_columns = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch']\n",
        "train_df.drop(columns=drop_columns, inplace=True)\n",
        "test_df.drop(columns=drop_columns, inplace=True)\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train_df.drop(columns=['Survived'])\n",
        "y = train_df['Survived']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train dataset shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation dataset shape:\", X_val.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2X0S4FTOMUn",
        "outputId": "0fc31a81-b68c-49a0-bc08-60d97d26da59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: (712, 10) (712,)\n",
            "Validation dataset shape: (179, 10) (179,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building ML Pipeline"
      ],
      "metadata": {
        "id": "EKgKv3_JOS1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define pipeline steps\n",
        "pipeline_steps = [\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('feature_selection', SelectKBest(score_func=f_classif)),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "]\n",
        "\n",
        "# Create pipeline object\n",
        "pipeline = Pipeline(steps=pipeline_steps)\n",
        "\n",
        "# Train the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "LBhVwI2vOV_B",
        "outputId": "a0dcb973-d77e-4a36-ad6a-5ada9825604f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('feature_selection', SelectKBest()),\n",
              "                ('classifier', RandomForestClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                (&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;feature_selection&#x27;, SelectKBest()),\n",
              "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                (&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;feature_selection&#x27;, SelectKBest()),\n",
              "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "PdkZeo5tOY-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Evaluate the trained model on the validation data\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPrY9DUpOayF",
        "outputId": "48e7504b-c0ed-406f-f52f-0e437b77dc74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85       105\n",
            "           1       0.79      0.76      0.77        74\n",
            "\n",
            "    accuracy                           0.82       179\n",
            "   macro avg       0.81      0.81      0.81       179\n",
            "weighted avg       0.81      0.82      0.82       179\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[90 15]\n",
            " [18 56]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference using ML Pipeline"
      ],
      "metadata": {
        "id": "67Mb8sjfOfag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained pipeline for inference on the test data\n",
        "test_predictions = pipeline.predict(test_df)\n",
        "\n",
        "# Generate predictions\n",
        "submission = pd.DataFrame({\n",
        "    \"PassengerId\": pd.read_csv(\"test.csv\")[\"PassengerId\"],\n",
        "    \"Survived\": test_predictions\n",
        "})\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "submission.to_csv(\"titanic_predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "x9KEmQjyOwtp"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}